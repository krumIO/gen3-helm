apiVersion: batch/v1
kind: CronJob
metadata:
  name: etl-cronjob
spec:
  schedule: "0 0 1 1 */5"
  jobTemplate:
    spec:
      backoffLimit: 0
      template:
        metadata:
          {{- with .Values.podAnnotations }}
          annotations:
            {{- toYaml . | nindent 12 }}
          {{- end }}
          labels:
            app: gen3job
        spec:
          shareProcessNamespace: true
          affinity:
            nodeAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
                - weight: 100
                  preference:
                    matchExpressions:
                      - key: karpenter.sh/capacity-type
                        operator: In
                        values:
                          - on-demand
                - weight: 99
                  preference:
                    matchExpressions:
                      - key: eks.amazonaws.com/capacityType
                        operator: In
                        values:
                          - ONDEMAND
          volumes:
            - name: signal-volume
              emptyDir: {}
            - name: creds-volume
              secret:
                secretName: "peregrine-dbcreds"
            - name: sshd-config
              configMap:
                name: sshd-config
            - name: ssh-pubkey
              secret:
                secretName: ssh-pubkey
            - name: etl-mapping
              configMap:
                name: etl-mapping
            - name: useryaml
              configMap:
                name: useryaml
            - name: hadoop
              configMap:
                name: tube-hadoop-config
          containers:
            - name: gen3-spark
              image: {{ .Values.image.spark.repository }}:{{ .Values.image.spark.tag }}
              ports:
              - containerPort: 22
              - containerPort: 9000
              - containerPort: 8030
              - containerPort: 8031
              - containerPort: 8032
              - containerPort: 8080
              - containerPort: 8081
              - containerPort: 7077
              - containerPort: 9870
              - containerPort: 8088
              - containerPort: 8042
              - containerPort: 8044
              - containerPort: 50070
              - containerPort: 10020
              - containerPort: 19888
              readinessProbe:
                tcpSocket:
                  port: 9000
                initialDelaySeconds: 10
                periodSeconds: 30
              env:
              - name: HADOOP_URL
                value: hdfs://0.0.0.0:9000
              - name: HADOOP_HOST
                value: 0.0.0.0
              - name: HADOOP_YARN_HOME
                value: /hadoop
              - name: YARN_HOME
                value: /hadoop
              - name: JAVA_HOME
                value: /usr/lib/jvm/java-8-openjdk-amd64/
              - name: HADOOP_OPTS
                value: "${HADOOP_OPTS} --add-modules java.activation"
              volumeMounts:
              - name: sshd-config
                mountPath: /etc/ssh/sshd_config
                subPath: sshd_config
                readOnly: false
              - name: sshd-config
                mountPath: /gen3spark/yarn-site.xml
                subPath: yarn-site.xml
                readOnly: false
              - name: sshd-config
                mountPath: /gen3spark/hdfs-site.xml
                subPath: hdfs-site.xml
                readOnly: false
              - name: sshd-config
                mountPath: /gen3spark/mapred-site.xml
                subPath: mapred-site.xml
                readOnly: false
              - name: ssh-pubkey
                mountPath: /tmp/sparkssh/authorized_keys
                subPath: authorized_keys
                readOnly: true
              imagePullPolicy: {{ .Values.image.spark.pullPolicy }}
              resources:
                {{- toYaml .Values.resources.spark | nindent 16 }}
              command: ["/bin/bash" ]
              args: 
                - "-c"
                - |
                  # trap 'exit 0' SIGINT SIGQUIT SIGTERM
                  # get /usr/local/share/ca-certificates/cdis-ca.crt into system bundle
                  ssh-keygen -t ed25519 -N '' -f /root/.ssh/id_ed25519 <<<y >/dev/null 2>&1
                  cat /root/.ssh/id_ed25519.pub >> /root/.ssh/authorized_keys
                  cat /tmp/sparkssh/authorized_keys >> /root/.ssh/authorized_keys
                  service ssh start
                  /usr/sbin/sshd -D
                  update-ca-certificates
                  cp /gen3spark/yarn-site.xml /hadoop/etc/hadoop/yarn-site.xml
                  cp /gen3spark/hdfs-site.xml /hadoop/etc/hadoop/hdfs-site.xml
                  cp /gen3spark/mapred-site.xml /hadoop/etc/hadoop/mapred-site.xml
                  python run_config.py
                  hdfs namenode -format
                  hdfs --daemon start namenode
                  hdfs --daemon start datanode
                  yarn --daemon start resourcemanager
                  yarn --daemon start nodemanager
                  hdfs dfsadmin -safemode leave
                  hdfs dfs -mkdir /result
                  hdfs dfs -mkdir /jars
                  hdfs dfs -mkdir /archive
                  /bin/bash /spark/sbin/start-all.sh
                  mapred historyserver
                  while true; do sleep 5; done
            - name: tube
              imagePullPolicy: IfNotPresent
              # image: quay.io/cdis/tube:feat_helm_test
              image: {{ .Values.image.tube.repository }}:{{ .Values.image.tube.tag }}
              ports:
                - containerPort: 80
              env:
                - name: DICTIONARY_URL
                  value: http://revproxy-service/dictionary_schema
                - name: ES_URL
                  value: gen3-elasticsearch-master
                - name: ES_INDEX_NAME
                  value: dev_etl
                - name: HADOOP_URL
                  value: hdfs://localhost:9000
                - name: HADOOP_HOST
                  value: localhost
                - name: HADOOP_CLIENT_OPTS
                  value: -Xmx1g
                - name: SPARK_EXECUTOR_MEMORY
                  value: 4g
                - name: SPARK_DRIVER_MEMORY
                  value: 6g
                - name: PGHOST
                  valueFrom:
                    secretKeyRef:
                      name: sheepdog-dbcreds
                      key: host
                      optional: false
                - name: PGPORT
                  valueFrom:
                    secretKeyRef:
                      name: sheepdog-dbcreds
                      key: port
                      optional: false  
                - name: PGUSER
                  value: postgres
                - name: PGPASSWORD
                  valueFrom:
                    secretKeyRef:
                      name: {{ .Values.global.postgres.existingSecret | default (printf "%s-postgresql" .Release.Name) }}
                      key: postgres-password
                      optional: false
                - name: PGDB
                  valueFrom:
                    secretKeyRef:
                      name: sheepdog-dbcreds
                      key: database
                      optional: false
                - name: DBREADY
                  valueFrom:
                    secretKeyRef:
                      name: sheepdog-dbcreds
                      key: dbcreated
                      optional: false
                # - name: ETL_FORCED
                #   value: "TRUE"
                # - name: gen3Env
                #   valueFrom:
                #     configMapKeyRef:
                #       name: manifest-global
                #       key: hostname
                # - name: slackWebHook
                #   valueFrom:
                #     configMapKeyRef:
                #       name: global
                #       key: slack_webhook
                #       optional: true
              volumeMounts:
                # - name: "creds-volume"
                #   readOnly: true
                #   mountPath: "/gen3/tube/creds.json"
                #   subPath: creds.json
                # Volume to signal when to kill spark
                - mountPath: /usr/share/pod
                  name: signal-volume
                - name: etl-mapping
                  readOnly: true
                  mountPath: "/tube/tube/settings.py"
                  subPath: settings.py
                - name: etl-mapping
                  readOnly: true
                  mountPath: "/gen3/tube/settings.py"
                  subPath: settings.py
                - name: etl-mapping
                  readOnly: true
                  mountPath: "/gen3/tube/etlMapping.yaml"
                  subPath: etlMapping.yaml
                - name: useryaml
                  mountPath: "/gen3/tube/user.yaml"
                  subPath: useryaml
                - name: hadoop
                  mountPath: /tube/yarn-site.xml
                  subPath: yarn-site.xml
                  readOnly: false
                - name: hadoop
                  mountPath: /tube/mapred-site.xml
                  subPath: mapred-site.xml
                  readOnly: false
                - name: hadoop
                  mountPath: /tube/hdfs-site.xml
                  subPath: hdfs-site.xml
                  readOnly: false
              resources:
                {{- toYaml .Values.resources.tube | nindent 16 }}
              command: ["/bin/bash"]
              args:
                - "-c"
                - |
                  while ! bash -c "echo >/dev/tcp/localhost/9000"; do
                    echo "Spark is not ready on port 9000... waiting for 10 seconds."
                    sleep 10
                  done

                  # Port 9000 is open, continue with the rest of the script
                  echo "Port 9000 is now open. Continuing with the script..."

                  ssh-keygen -t ed25519 -N '' -f /root/.ssh/id_ed25519 <<<y >/dev/null 2>&1
                  cat /root/.ssh/id_ed25519.pub
                  cp /tube/yarn-site.xml /hadoop/etc/hadoop/yarn-site.xml
                  cp /tube/mapred-site.xml /hadoop/etc/hadoop/mapred-site.xml
                  cp /tube/hdfs-site.xml /hadoop/etc/hadoop/hdfs-site.xml

                  echo "python run_config.py && python run_etl.py"
                  python run_config.py

                  VERSION=v4.35.2
                  BINARY=yq_linux_amd64
                  wget https://github.com/mikefarah/yq/releases/download/${VERSION}/${BINARY}.tar.gz -O - |\
                    tar xz && mv ${BINARY} /usr/bin/yq

                  n=$(yq eval '.mappings | length' < /gen3/tube/etlMapping.yaml)
                  echo $n
                  for ((i = 0 ; i <=$(($n + 0)) ; i++)); 
                  do
                    echo $i
                    echo "$(yq eval ".mappings |= .[$(($i - 1)):$i]" < /gen3/tube/etlMapping.yaml)" > /gen3/tube/etl_current.yaml
                    cat /gen3/tube/etl_current.yaml
                    python run_etl.py -s transform
                  done

                  exitcode=$?
                  
                  # Kill sidecar and all processes
                  echo "Exit code: $exitcode"
                  pkill -u root && exit $exitcode
                  exit "$exitcode" &
          restartPolicy: Never